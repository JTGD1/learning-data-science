{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised segmentation and tree-structured models\n",
    "Data Mining for Business Analytics\n",
    "\n",
    "Robert Moakler, Spring 2016\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, I am going to `import` some Python packages that I will use for this Hands-on demonstration. I have removed a lot of the code that is not necessary for you to know and put it into something called `dmba`. This means that anything starting with `dmba` will be something I wrote but understanding the code behind it is not needed. If you like to look at stuff like this, feel free to look inside of the `moakler` folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import our custom functions to do some cool Hand-on stuff\n",
    "from moakler import dmba\n",
    "\n",
    "# Import pandas to read in data\n",
    "import pandas as pd\n",
    "\n",
    "# Import packages to plot\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "We need to look at some data, so let's read in the data set that is located in `data/success.csv`. There are 500 records and three features. Two decimal numbers: number_of_pets and age and a binary (0 or 1) columns called success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/success.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can (and should) take a look at the first few rows/records of our data to see what we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a very important business problem. In this example I would like to use `number_of_pets` and `age` to predict whether or not someone will be successful. Like we discussed last week, we will often separate the features used for prediction from the target variable. Often, we call the features **`X`** and the target variable **`Y`**. There is no real reason for this, but it is very common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = data['success']\n",
    "X = data.drop(['success'], 1) # this will drop the column success\n",
    "                              # the column name must be in [] and you must have a 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take one more look at our nicely separated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature segmentation\n",
    "Let's look at one of our features, in this case `number_of_pets` and try to figure out where the best split should be to create pure groups. To visualize this, I will plot the points on a number line. Red dots mean unsuccessful people and blue dots mean successful people. The vertical position here doesn't mean anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dmba.single_feature_plot(X, Y, 'number_of_pets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where do you think the best split should be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dmba.information_gain(X, Y, 'number_of_pets', threshold=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through all possible splits and find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dmba.get_highest_ig(X, Y, 'number_of_pets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a tree\n",
    "Instead of going through each group and manually calculating the information gain, we will just ask Python to do it. We simply need to tell the tree to use \"entropy\" since that's what we've been talking about. As we saw in the slides, we can also change the max depth of the tree so that it doesn't get too tall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import decision tree related things\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Tell Python what type of model we are interested in building\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "\n",
    "# Now you should build (also called train or fit) the model\n",
    "tree = tree.fit(X, Y)\n",
    "\n",
    "# Since it is a tree, we can use this thing I wrote to look at the tree\n",
    "dmba.print_tree(tree)\n",
    "\n",
    "# We can also use something else I wrote to look at the decision surface\n",
    "dmba.decision_surface(X, Y, tree)\n",
    "\n",
    "# Check to see how accurate our tree is using accuracy\n",
    "accuracy = accuracy_score(tree.predict(X), Y)\n",
    "print \"Accuracy = \" + str(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team work\n",
    "I would like you to try and answer this question with your closest 2 or 3 neighbors. Work in groups and try to find a solution. While discussing, try to ensure everyone knows why you are taking the approach that you are taking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a few different values of `max_depth` and find out which one gives you the best accuracy. To do this\n",
    "- loop through values from `max_depth`, maybe the numbers 1 through 20\n",
    "- for each value, tell Python to make a tree with that max depth\n",
    "- for each value's tree, fit/train/build your tree with all of our `X` and `Y` data\n",
    "- for each fitted tree, find the accuracy\n",
    "- keep track of all accuracies for each max depth (maybe in a list)\n",
    "\n",
    "Now, to visualize how you are doing, create a plot of accuracies. On the x-axis put the values of `max_depth` you tried (i.e., the numbers 1 through 20). On the y-axis put your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'll start you off with some helpful skeleton code\n",
    "\n",
    "max_depths = range(1,20)\n",
    "accuracies = []\n",
    "\n",
    "for md in max_depths:\n",
    "    # Tell Python what type of model we are interested in building\n",
    "    \n",
    "    # Now you should build (also called train or fit) the model\n",
    "    \n",
    "    # Check to see how accurate our tree is using accuracy\n",
    "\n",
    "plt.plot(<list_of_x_values>, <list_of_y_values>)\n",
    "plt.xlabel(\"Label of x-axis\")\n",
    "plt.ylabel(\"Label of y-axis\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
