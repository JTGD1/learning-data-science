{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining for Business Analytics\n",
    "## Homework 2 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Solutions\n",
    "\n",
    "Student Netid: Solutions\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data Mining\n",
    "1\\. For each of the following examples, tell me whether they are describing \"Data Mining\" or \"Data Mining in Use\". For \"Data Mining\" tasks, please replace **`ANS`** with **`DM`**. For \"Data Mining in Use\", please replace it with **`USE`**. **[*3 points each*]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) [**`DM`**] Building a decision tree to predict if users will cancel their cell phone plan in the next billing cycle.\n",
    "\n",
    "b) [**`DM`**] Using the attributes of my data to find clusters of users that may be beneficial to my business.\n",
    "\n",
    "c) [**`USE`**] Processing 1,000 new applicants through a logistic regression to determine if I should grant them a loan.\n",
    "\n",
    "d) [**`USE`**] Predict whether a customer is pregnant.\n",
    "\n",
    "e) [**`DM`**] Find patterns indicating what customer behavior is more likely to lead to response to an on-line ad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Modeling\n",
    "As data scientists we will build many models both in class and in the real world. So far this semester we have learned a few different types of models: decision trees, logistic regression, SVMs, and linear regressions. In your own words please explain what the *modeling phase* of the Data Mining Cycle is doing. Why do we even bother modeling? What is the point? What is our goal? **This explanation should be around 7 sentences.** Be precise but concise. **[*15 points*]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modeling phase of the data mining process is aiming to build a **simplified version of reality**. We want to create a representation of reality so that we can use models to classify or predict new data that we have never seen. Modeling will allow us to learn from out data and systematically apply what we have learned to new data. This allows us to make predictions using data and not simple intuition. Being able to predict new data is crucial to data mining and data science. If we can't use data to learn something about new data then we are not fully utilizing our data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Part 3: Decision Trees\n",
    "For these problems calculate the given quantity. There are two possible classes in Question 1 and three possible classes in Questions 2 and 3. Since calculations of entropy only require us to use logs and basic multiplication, you should be able to easily show your work by typing. **Answers without work will be given at most half credit.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Consider this population. What is the entropy? **[*8 points*]**.\n",
    "<br /><img src=\"images/q3-1.png\" height=144px width=142px style=\"float: left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "entropy &= -p_1log_2(p_1) - p_2log_2(p_2) \\\\\n",
    "        &= -0.4log_2(0.4) - 0.6log_2(0.6) \\\\\n",
    "        &= -0.4(-1.322) - 0.6(-0.737) \\\\\n",
    "        &= 0.971\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Consider this population. What is the entropy? **[*8 points*]**.\n",
    "<br /><img src=\"images/q3-2.png\" height=144px width=142px style=\"float: left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "entropy &= -p_1log_2(p_1) - p_2log_2(p_2) - p_3log_2(p_3) \\\\\n",
    "        &= -0.266log_2(0.266) - 0.4log_2(0.4) - 0.33log_2(0.33) \\\\\n",
    "        &= -0.266(-1.911) - 0.4(-1.322) - 0.33(-1.600) \\\\\n",
    "        &= 1.560\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Consider these two potential splits on the first node of a decision tree. Calculate the information gain obtained with Split A and Split B. Which split is more desirable? Why? **[*14 points*]**.\n",
    "<br /><img src=\"images/q3-3a.png\" height=300px width=300px style=\"float: left; padding-right: 20px;\"/> <img src=\"images/q3-3b.png\" height=300px width=300px style=\"float: left; padding-left: 20px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$IG = entropy(parent) - [p(child_1) \\cdot entropy(child_1) + p(child_2) \\cdot entropy(child_2)]$\n",
    "\n",
    "We already know the entropy of the parent from Question 2 is 1.56.\n",
    "\n",
    "Split A:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "entropy(child_1) &= -0.625log_2(0.625) - 0.375log_2(0.375) \\\\\n",
    "                 &= -0.625(-0.678) - 0.375(-1.415) \\\\\n",
    "                 &= 0.954 \\\\\n",
    "entropy(child_2) &= -0.143log_2(0.143) - 0.143log_2(0.143) - 0.714log_2(0.714) \\\\\n",
    "                 &= -0.143(-2.806) - 0.143(-2.806) - 0.714(-0.486) \\\\\n",
    "                 &= 1.150 \\\\\n",
    "IG &= 1.56 - \\Big(\\frac{8}{15} \\cdot 0.954 + \\frac{7}{15} \\cdot 1.150\\Big) \\\\\n",
    "   &= 1.56 - 1.045 \\\\\n",
    "   &= 0.515\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Split B:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "entropy(child_1) &= -1log_2(1.0) \\\\\n",
    "                 &= -1(0) \\\\\n",
    "                 &= 0 \\\\\n",
    "entropy(child_2) &= -0.44log_2(0.44) - 0.55log_2(0.55) \\\\\n",
    "                 &= -0.44(-1.184) - 0.55(-0.862) \\\\\n",
    "                 &= 0.995 \\\\\n",
    "IG &= 1.56 - \\Big(\\frac{6}{15} \\cdot 0 + \\frac{9}{15} \\cdot 0.995\\Big) \\\\\n",
    "   &= 1.56 - 0.597 \\\\\n",
    "   &= 0.963\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We should prefer Split B since it leads to large information gain! We get more information from this split than the the first split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Decision trees vs. Linear discriminant models\n",
    "What are the similarities and differences of decision trees and linear discriminant models? When might you prefer to use one over another? **This explanation should be around 7 sentences.** Be precise but concise. **[*15 points*]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees and linear discriminant models are both types of models that we use to build simplified representations of reality. Both models create linear boundaries, but decision trees are restricted to only building boundaries that are *perpendicular* whereas linear discriminant models can build a linear boundary at any angle. Additionally, decision trees are able to create *many* boundaries for one problem while a linear discriminant model may only build a single boundary. This means that decision trees are able to create more precise decision surfaces which can help fit non-smooth data! Trees are also generally easier to understand and explain to others --- they can be thought of as simple rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5. Hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your hands-on excercise, I am going to ask you to build two different models and show me the impact of training/fitting them with different amounts of data. For this example we will be using the `data/cell2cell.csv` data.\n",
    "\n",
    "These historical data consist of 31,892 customers: 15,855 customers that churned (i.e., left the company) and 16,036 that did not churn. Here are the data set's 12 columns:\n",
    "\n",
    "```\n",
    "Col.  Var. Name  Var. Description\n",
    "----- ---------- --------------------------------------------------------------\n",
    "1     revenue    Mean monthly revenue in dollars\n",
    "2     outcalls   Mean number of outbound voice calls\n",
    "3     incalls    Mean number of inbound voice calls\n",
    "4     months     Months in Service\n",
    "5     eqpdays    Number of days the customer has had his/her current equipment\n",
    "6     webcap     Handset is web capable\n",
    "7     marryyes   Married (1=Yes; 0=No)\n",
    "8     travel     Has traveled to non-US country (1=Yes; 0=No)\n",
    "9     pcown      Owns a personal computer (1=Yes; 0=No)\n",
    "10    creditcd   Possesses a credit card (1=Yes; 0=No)\n",
    "11    retcalls   Number of calls previously made to retention team\n",
    "12    churndep   Did the customer churn (1=Yes; 0=No)\n",
    "```\n",
    "\n",
    "The first 11 columns are our attributes/features. The last column, `\"churndep\"`, is the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. I would like for you to create a decision tree using entropy with no max depth and a logistic regression. For each of these models, I would like you to assign 10% to 90% of the data to training (in increments of 10%) and the rest to test. For each training set, I would like you to fit both models and then get the accuracy on the remaining data used for test for both models. Finally, create a plot where the x-axis includes 0.10 to 0.90 (one tick for each training data percentage) and the y-axis indicates accuracy. Your plot should have two lines/curves on it: one for the decision tree and one for logistic regression. Remember to put a legend. **[*15 points*]**.\n",
    "\n",
    "*Hint: This should look somewhat similar to the team work we did in the Hands-on material in Module 4.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10ca60f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfaWUcpH/B8uPuLW9SjudAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c35cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in our csv data\n",
    "data = pd.read_csv(\"data/cell2cell.csv\")\n",
    "\n",
    "# Put all features into X and the target variable into Y\n",
    "X = data.drop([\"churndep\"], 1)\n",
    "Y = data[\"churndep\"]\n",
    "\n",
    "# Prepare to do some training and testing\n",
    "training_percentages = [0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90]\n",
    "tree_accuracies = []\n",
    "logistic_accuracies = []\n",
    "\n",
    "# Loop through your training percentages, split your data with each percentage, \n",
    "#  create both models, fit/train both models, predict with your models and \n",
    "#  append each accuracy to the correct list\n",
    "for training_percentage in training_percentages:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = training_percentage)\n",
    "    \n",
    "    # Create both models\n",
    "    tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "    logistic = LogisticRegression()\n",
    "    \n",
    "    # Fit both models\n",
    "    tree.fit(X_train, Y_train)\n",
    "    logistic.fit(X_train, Y_train)\n",
    "    \n",
    "    # Get predictions from both models\n",
    "    Y_test_predicted_tree = tree.predict(X_test)\n",
    "    Y_test_predicted_logistic = logistic.predict(X_test)\n",
    "\n",
    "    # Get the accuracy for the models' predictions\n",
    "    tree_acc = accuracy_score(Y_test_predicted_tree, Y_test)\n",
    "    logistic_acc = accuracy_score(Y_test_predicted_logistic, Y_test)\n",
    "    \n",
    "    # Now that I have a tree and logistic accuracy, I should add them to my list of accuracies\n",
    "    tree_accuracies.append(tree_acc)\n",
    "    logistic_accuracies.append(logistic_acc)\n",
    "    \n",
    "# Plot two curves on one plot. Don't forget labels and your legend\n",
    "plt.plot(training_percentages, tree_accuracies, label=\"Tree\")\n",
    "plt.plot(training_percentages, logistic_accuracies, label=\"Logistic\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Is this a learning curve or a fitting curve? What is the difference? What does each one show us? **[*5 points*]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a learning curve. In a learning curve we use different amounts of training data and plot the results of our model on the hold-out data. Learning curves hold the model complexity constant. A fitting curve would hold the amount of training data constant and would plot hold-out performance for different model complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. What do you observe in the above graph? Anything interesting? There is no right answer. In fact, you will most likely see a different (although possibly similar) plot when compared to your friends. Why do you think each person's plot will look different? If you were to rerun the cell above this, you would probably get a different plot again. Why do you think this is the case? **[*5 points*]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that varying the amount of training data seems to lead to very small fluctuations in performance. We generally only see a variance in about 1%. Additionally, we see that the logistic model outperforms the tree model in all cases!\n",
    "\n",
    "Different results will occur due to different train/test splits. This is a random process! Depending on what data is assigned to training or testing, we can see drastically different results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
